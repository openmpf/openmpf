// NOTICE
//
// This software (or technical data) was produced for the U.S. Government
// under contract, and is subject to the Rights in Data-General Clause
// 52.227-14, Alt. IV (DEC 2007).
//
// Copyright 2023 The MITRE Corporation. All Rights Reserved.


// Copyright 2023 The MITRE Corporation
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package org.mitre.mpf.wfm.buffers;

import "algorithmproperty.proto";

option java_outer_classname = "DetectionProtobuf";

enum DetectionError {
    NO_DETECTION_ERROR             = 0;
    DETECTION_NOT_INITIALIZED      = 1;
    UNSUPPORTED_DATA_TYPE          = 2;
    COULD_NOT_OPEN_DATAFILE        = 3;
    COULD_NOT_READ_DATAFILE        = 4;
    FILE_WRITE_ERROR               = 5;
    BAD_FRAME_SIZE                 = 6;
    DETECTION_FAILED               = 7;
    MISSING_PROPERTY               = 8;
    INVALID_PROPERTY               = 9;
    MEMORY_ALLOCATION_FAILED       = 10;
    UNRECOGNIZED_DETECTION_ERROR   = 11;
    REQUEST_CANCELLED              = 12; // The detection request was cancelled by the user.
    DEAD_LETTER                    = 13;
    GPU_ERROR                      = 14;
    NETWORK_ERROR                  = 15;
    COULD_NOT_OPEN_MEDIA           = 16;
    COULD_NOT_READ_MEDIA           = 17;
}

message PropertyMap {
    string key = 1;
    string value = 2;
}

message GenericTrack {
    float confidence = 1;
    repeated PropertyMap detection_properties = 2;
}

message ImageLocation {
    int32 x_left_upper = 1;
    int32 y_left_upper = 2;
    int32 width = 3;
    int32 height = 4;
    float confidence = 5;
    repeated PropertyMap detection_properties = 6;
}

message VideoTrack {
    int32 start_frame = 1;
    int32 stop_frame = 2;

    // TODO: Upgrade development env to proto3 and use the following syntax:
    // map<int32, ImageLocation> frame_locations = 3;

    // Define a FrameLocationMap for now so that everything works with proto2.
    message FrameLocationMap {
      int32 frame = 1;
      ImageLocation image_location = 2;
    }
    repeated FrameLocationMap frame_locations = 3;

    float confidence = 4;
    repeated PropertyMap detection_properties = 5;
}

message AudioTrack {
    int32 start_time = 1;
    int32 stop_time = 2;
    float confidence = 3;
    repeated PropertyMap detection_properties = 4;
}

message DetectionRequest {
    // A unique identifier for this request.
    int64 request_id = 1;

    // The path (not URI or URL) to the medium to process.
    string data_uri = 2;

    enum DataType {
        UNKNOWN = 0;
        VIDEO = 1;
        IMAGE = 2;
        AUDIO = 3;
    }

    DataType data_type = 3;

    repeated AlgorithmProperty algorithm_property = 4;

    // The ID of the medium to process. Many requests may have the same ID.
    int64 media_id = 400;

    // The current task index in the pipeline.
    int32 task_index = 401;

    // The name of the current task in the pipeline.
    string task_name = 402;

    // The index of the action in the current task of the pipeline.
    int32 action_index = 403;

    // The name of the action which was used to create this request.
    string action_name = 404;

    repeated PropertyMap media_metadata = 405;

    message GenericRequest {
        // The track generated by a previous task in a feed-forward pipeline.
        GenericTrack feed_forward_track = 1;
    }
    GenericRequest generic_request = 500;

    message VideoRequest {
        // The zero-based start frame in the video.
        int32 start_frame = 1;

        // The zero-based and inclusive stop frame to process in the video.
        int32 stop_frame = 2;

        // The track generated by a previous task in a feed-forward pipeline.
        VideoTrack feed_forward_track = 3;
    }
    VideoRequest video_request = 501;

    message AudioRequest {
        // The start time in the audio or video file.
        int32 start_time = 1;

        // The stop time to process in the audio or video file.
        int32 stop_time = 2;

        // The track generated by a previous task in a feed-forward pipeline.
        AudioTrack feed_forward_track = 3;
    }
    AudioRequest audio_request = 502;

    message ImageRequest {
        // The detection location generated by a previous task in a
        // feed-forward pipeline.
        ImageLocation feed_forward_location = 1;
    }
    ImageRequest image_request = 503;
}

message DetectionResponse {
    int64 request_id = 1;

    enum DataType {
        UNKNOWN = 0;
        VIDEO = 1;
        IMAGE = 2;
        AUDIO = 3;
    }

    DataType data_type = 2;

    DetectionError error = 3;

    string error_message = 4;

    // Copied from the request.
    int64 media_id = 400;

    // Copied from the request.
    int32 task_index = 401;

    // Copied from the request.
    string task_name = 402;

    // Copied from the request.
    int32 action_index = 403;

    // Copied from the request.
    string action_name = 404;

    reserved 405; // optional MetricsMessage metrics = 405;


    message GenericResponse {
        repeated GenericTrack generic_tracks = 1;
    }
    repeated GenericResponse generic_responses = 500;

    message VideoResponse {
        int32 start_frame = 1;
        int32 stop_frame = 2;

        repeated VideoTrack video_tracks = 3;
    }
    repeated VideoResponse video_responses = 501;

    message AudioResponse {
        int32 start_time = 1;
        int32 stop_time = 2;

        repeated AudioTrack audio_tracks = 3;
    }
    repeated AudioResponse audio_responses = 502;

    message ImageResponse {
        repeated ImageLocation image_locations = 1;
    }
    repeated ImageResponse image_responses = 503;
}

//// Used for streaming video job segment summary message

message StreamingVideoDetection {
    int32 frame_number = 1;
    int64 time = 2;

    int32 x_left_upper = 3;
    int32 y_left_upper = 4;
    int32 width = 5;
    int32 height = 6;

    float confidence = 7;

    repeated PropertyMap detection_properties = 8;
}


message StreamingVideoTrack {
    int32 start_frame = 1;
    int64 start_time = 2;

    int32 stop_frame = 3;
    int64 stop_time = 4;

    float confidence = 5;

    repeated StreamingVideoDetection detections = 6;

    repeated PropertyMap detection_properties = 7;
}


message StreamingDetectionResponse {

    string error = 1;

    int32 segment_number = 2;

    int32 segment_start_frame = 3; // Start frame relative to the
                                            // beginning of stream processing:
                                            // segment 0 will start with frame 0

    int32 segment_stop_frame = 4;

    repeated StreamingVideoTrack video_tracks = 5;

    reserved 400; // optional MetricsMessage metrics = 400;
}
