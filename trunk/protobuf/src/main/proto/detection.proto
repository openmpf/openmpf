// NOTICE
//
// This software (or technical data) was produced for the U.S. Government
// under contract, and is subject to the Rights in Data-General Clause
// 52.227-14, Alt. IV (DEC 2007).
//
// Copyright 2023 The MITRE Corporation. All Rights Reserved.


// Copyright 2023 The MITRE Corporation
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package org.mitre.mpf.wfm.buffers;

option java_outer_classname = "DetectionProtobuf";

enum DetectionError {
    NO_DETECTION_ERROR             = 0;
    DETECTION_NOT_INITIALIZED      = 1;
    UNSUPPORTED_DATA_TYPE          = 2;
    COULD_NOT_OPEN_DATAFILE        = 3;
    COULD_NOT_READ_DATAFILE        = 4;
    FILE_WRITE_ERROR               = 5;
    BAD_FRAME_SIZE                 = 6;
    DETECTION_FAILED               = 7;
    MISSING_PROPERTY               = 8;
    INVALID_PROPERTY               = 9;
    MEMORY_ALLOCATION_FAILED       = 10;
    UNRECOGNIZED_DETECTION_ERROR   = 11;
    REQUEST_CANCELLED              = 12; // The detection request was cancelled by the user.
    DEAD_LETTER                    = 13;
    GPU_ERROR                      = 14;
    NETWORK_ERROR                  = 15;
    COULD_NOT_OPEN_MEDIA           = 16;
    COULD_NOT_READ_MEDIA           = 17;
}

message GenericTrack {
    float confidence = 1;
    map<string, string> detection_properties = 2;
}

message ImageLocation {
    int32 x_left_upper = 1;
    int32 y_left_upper = 2;
    int32 width = 3;
    int32 height = 4;
    float confidence = 5;
    map<string, string> detection_properties = 6;
}

message VideoTrack {
    int32 start_frame = 1;
    int32 stop_frame = 2;

    map<int32, ImageLocation> frame_locations = 3;

    float confidence = 4;
    map<string, string>  detection_properties = 5;
}

message AudioTrack {
    int32 start_time = 1;
    int32 stop_time = 2;
    float confidence = 3;
    map<string, string>  detection_properties = 4;
}

message DetectionRequest {
    // The path to the medium to process.
    string media_path = 1;

    map<string, string>  algorithm_properties = 2;

    // The ID of the medium to process.
    int64 media_id = 3;

    // The current task index in the pipeline.
    int32 task_index = 4;

    // The index of the action in the current task of the pipeline.
    int32 action_index = 5;

    map<string, string> media_metadata = 6;

    oneof request_type {
        GenericRequest generic_request = 7;
        VideoRequest video_request = 8;
        AudioRequest audio_request = 9;
        ImageRequest image_request = 10;
    }

    message GenericRequest {
        // The track generated by a previous task in a feed-forward pipeline.
        GenericTrack feed_forward_track = 1;
    }

    message VideoRequest {
        // The zero-based start frame in the video.
        int32 start_frame = 1;

        // The zero-based and inclusive stop frame to process in the video.
        int32 stop_frame = 2;

        // The track generated by a previous task in a feed-forward pipeline.
        VideoTrack feed_forward_track = 3;
    }

    message AudioRequest {
        // The start time in the audio or video file.
        int32 start_time = 1;

        // The stop time to process in the audio or video file.
        int32 stop_time = 2;

        // The track generated by a previous task in a feed-forward pipeline.
        AudioTrack feed_forward_track = 3;
    }

    message ImageRequest {
        // The detection location generated by a previous task in a
        // feed-forward pipeline.
        ImageLocation feed_forward_location = 1;
    }
}

message DetectionResponse {
    DetectionError error = 1;

    string error_message = 2;

    // Copied from the request.
    int64 media_id = 3;

    // Copied from the request.
    int32 task_index = 4;

    // Copied from the request.
    int32 action_index = 5;

    oneof response_type {
        GenericResponse generic_response = 6;
        VideoResponse video_response = 7;
        AudioResponse audio_response = 8;
        ImageResponse image_response = 9;
    }


    message GenericResponse {
        repeated GenericTrack generic_tracks = 1;
    }

    message VideoResponse {
        int32 start_frame = 1;
        int32 stop_frame = 2;

        repeated VideoTrack video_tracks = 3;
    }

    message AudioResponse {
        int32 start_time = 1;
        int32 stop_time = 2;

        repeated AudioTrack audio_tracks = 3;
    }
    message ImageResponse {
        repeated ImageLocation image_locations = 1;
    }
}

//// Used for streaming video job segment summary message

message StreamingVideoDetection {
    int32 frame_number = 1;
    int64 time = 2;

    int32 x_left_upper = 3;
    int32 y_left_upper = 4;
    int32 width = 5;
    int32 height = 6;

    float confidence = 7;

    map<string, string>  detection_properties = 8;
}


message StreamingVideoTrack {
    int32 start_frame = 1;
    int64 start_time = 2;

    int32 stop_frame = 3;
    int64 stop_time = 4;

    float confidence = 5;

    repeated StreamingVideoDetection detections = 6;

    map<string, string>  detection_properties = 7;
}


message StreamingDetectionResponse {

    string error = 1;

    int32 segment_number = 2;

    int32 segment_start_frame = 3; // Start frame relative to the
                                            // beginning of stream processing:
                                            // segment 0 will start with frame 0

    int32 segment_stop_frame = 4;

    repeated StreamingVideoTrack video_tracks = 5;
}
