#############################################################################
# NOTICE                                                                    #
#                                                                           #
# This software (or technical data) was produced for the U.S. Government    #
# under contract, and is subject to the Rights in Data-General Clause       #
# 52.227-14, Alt. IV (DEC 2007).                                            #
#                                                                           #
# Copyright 2021 The MITRE Corporation. All Rights Reserved.                #
#############################################################################

#############################################################################
# Copyright 2021 The MITRE Corporation                                      #
#                                                                           #
# Licensed under the Apache License, Version 2.0 (the "License");           #
# you may not use this file except in compliance with the License.          #
# You may obtain a copy of the License at                                   #
#                                                                           #
#    http://www.apache.org/licenses/LICENSE-2.0                             #
#                                                                           #
# Unless required by applicable law or agreed to in writing, software       #
# distributed under the License is distributed on an "AS IS" BASIS,         #
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  #
# See the License for the specific language governing permissions and       #
# limitations under the License.                                            #
#############################################################################

######################
# Main Configuration #
######################

output.site.name=mpf1
amq.broker.uri=${env:ACTIVE_MQ_BROKER_URI}
mpf.output.objects.enabled=true
mpf.output.objects.artifacts.and.exemplars.only=false
mpf.output.objects.last.task.only=false
mpf.output.objects.censored.properties=S3_ACCESS_KEY,S3_SECRET_KEY,ACS_URL,ACS_SUBSCRIPTION_KEY,ACS_BLOB_CONTAINER_URL,ACS_BLOB_SERVICE_KEY

# The base location for all temporary files created by the WFM. This path will contain subdirectories which store
# local copies of remote media, output objects, extracted artifacts (i.e., frames), and marked-up media.
mpf.share.path=${env:MPF_HOME}/share
mpf.plugins.path=${env:MPF_HOME}/plugins


##################
# Object Storage #
##################
# Disables Nginx storage when not present
http.object.storage.nginx.service.uri=
#http.object.storage.nginx.service.uri=https://somehost:123543/somepath
http.object.storage.nginx.upload.thread.count=3
# Size is in bytes
http.object.storage.nginx.upload.segment.size=8388608
http.object.storage.upload.retry.count=6


#######
# JMX #
#######

# If set to true, any messages on the ActiveMQ queues will be purged between WFM restarts.
jmx.amq.broker.enabled=true
jmx.amq.broker.uri=service:jmx:rmi:///jndi/rmi://${env:ACTIVE_MQ_HOST}:1099/jmxrmi
jmx.amq.broker.admin.username=admin
jmx.amq.broker.admin.password=admin
# A comma-separated list of queues not to purge.
jmx.amq.broker.whiteList=MPF.DLQ_PROCESSED_MESSAGES,MPF.DLQ_INVALID_MESSAGES

#######################
# Version Information #
#######################
mpf.version.semantic=${env:MPF_VERSION:-6.2}
mpf.version.json.output.object.schema=6.1

##########################
# Database Configuration #
##########################
jdbc.driverClassName=org.postgresql.Driver
jdbc.url=${env:JDBC_URL:-jdbc:postgresql://localhost:5432/mpf}
jdbc.username=${env:POSTGRES_USER:-mpf}
jdbc.password=${env:POSTGRES_PASSWORD:-password}

hibernate.show.sql=false

#####################
# JMS Configuration #
#####################

jms.priority=4

###########################
# Detection Configuration #
###########################

##Artifact Extraction Policies

# Definition of which data types are to be considered "nonvisual" for the purposes
# of artifact extraction.
detection.artifact.extraction.nonvisual.types=MOTION,SPEECH,SCENE

# The policy for extracting artifacts (e.g., frames) from a medium. The value of
# this property MUST be one of the following choices:
#     NONE: No artifact extraction will be performed.
#     VISUAL_TYPES_ONLY: Extract artifacts only for tracks associated with a "visual" data
#                        type; i.e., this policy turns off artifact extraction for the data types
#                        listed in the detection.artifact.extraction.nonvisual.types property
#                        defined above.
#     ALL_TYPES: Extract artifacts regardless of data type.
#     ALL_DETECTIONS: Extract artifacts for all detections in the track.
#
# With the VISUAL_TYPES_ONLY or ALL_TYPES policy, artifacts will be extracted according to
# the detection.artifact.extraction.policy.* settings below. With the NONE and ALL_DETECTIONS
# policies, those settings are ignored.
detection.artifact.extraction.policy=VISUAL_TYPES_ONLY

# If true, an artifact will be extracted for each detection in each frame selected according to the artifact extraction
# policy properties that follow. The extracted artifact will be cropped to the width and height of the
# detection bounding box, instead of extracting the entire frame.  If false, the entire frame will be extracted.
detection.artifact.extraction.policy.cropping=true

# Extract the exemplar frame from the track, plus N frames before and after the exemplar.
# If N = 0, then only the exemplar frame will be extracted. If N > 0, then
# the exemplar frame plus N frames before and after it will be extracted, if they exist.
# If N < 0, then this property is disabled.
detection.artifact.extraction.policy.exemplar.frame.plus=0

# Extract the first frame from the track.
detection.artifact.extraction.policy.first.frame=false

# Extract the frame with a detection that is closest to the middle frame from the track.
detection.artifact.extraction.policy.middle.frame=false

#Extract the last frame from the track.
detection.artifact.extraction.policy.last.frame=false

# The detections in a track will be sorted by confidence and then the N detections with
# the highest confidence will be extracted, up to the number of available detections,
# where N is an integer greater than 0.
# If N is less than or equal to 0, then this policy is disabled.
detection.artifact.extraction.policy.top.confidence.count=0

# The number of artifacts to upload in parallel per piece of media.
detection.artifact.extraction.parallel.upload.count=10


# The DEFAULT sampling interval of a medium during detection. This may be overridden in a detection action by providing the
# FRAME_INTERVAL property. May be disabled by setting it <= 0.
detection.sampling.interval=1

# The DEFAULT confidence to expect from detections. This may be overridden in a detection action by providing the
# CONFIDENCE_THRESHOLD property.
detection.confidence.threshold=-1

# The DEFAULT frame rate cap system property. FRAME_RATE_CAP property can be used to set a threshold
# on the maximum number of frames to process within one second of the native video time.
# This may be overridden in a detection action by providing the FRAME_RATE_CAP property.
# May be disabled by setting it <= 0.
detection.frame.rate.cap=-1

# The DEFAULT minimum gap between two segments created by merging tracks from the previous detection task in a pipeline.
# If the gap between two segments is less than this value, they are merged. This value is only applicable in pipelines
# with multiple detection tasks. This may be overridden in a detection action by providing the MIN_GAP_BETWEEN_SEGMENTS
# property.
detection.segment.minimum.gap=10

# The DEFAULT preferred length of any segments sent to the detection components. This only applies
# to videos that have a constant frame rate. This may be overridden in a detection
# action by providing the TARGET_SEGMENT_LENGTH property.
detection.segment.target.length=200

# The DEFAULT preferred length of any segments sent to the detection components.
# This only applies to videos with a variable frame rate. This may be overridden in a detection
# action by providing the VFR_TARGET_SEGMENT_LENGTH property.
detection.vfr.segment.target.length=400

# The DEFAULT minimum length of any segments sent to the detection components. Must be less than segment.target.length.
# This only applies to videos that have a constant frame rate.
# This may be overridden in a detection action by providing the MIN_SEGMENT_LENGTH property.
detection.segment.minimum.length=20

# The DEFAULT minimum length of any segments sent to the detection components. Must be less than segment.target.length.
# This only applies to videos that have a variable frame rate.
# This may be overridden in a detection action by providing the VFR_MIN_SEGMENT_LENGTH property.
detection.vfr.segment.minimum.length=40

# The DEFAULT value for enabling or disabling labeling tracks as moving or not moving.
# This may be overridden in a detection action by providing the MOVING_TRACK_LABELS_ENABLED property.
detection.moving.track.labels.enabled=false

# The DEFAULT value for enabling or disabling removal of tracks labeled as not moving.
# This may be overridden in a detection action by providing the MOVING_TRACKS_ONLY property.
detection.moving.track.outputs.only=false

# The DEFAULT maximum intersection over union(IoU) overlap between detection bounding boxes and
# the average per-track bounding box for objects to be considered moving. Value is expected to be
# between 0 and 1. Note that the lower IoU, the more likely the object is moving. This may be
# overridden in a detection action by providing the MOVING_TRACK_MAX_IOU property.
detection.moving.track.max.iou=0.70

# The DEFAULT minimum number of moving detections for a track to be labeled as moving. This may be
# overridden in a detection action by providing the MOVING_TRACK_MIN_DETECTIONS property.
detection.moving.track.min.detections=2

# The DEFAULT value for enabling or disabling track merging across segments. This may be overridden in a detection action
# by providing the MERGE_TRACKS property.
detection.video.track.merging.enabled=false

# The DEFAULT minimum gap between similar tracks reported by the detection components. Tracks less than this distance
# apart will be merged into a single track. This may be overridden in a detection action by providing the
# MIN_GAP_BETWEEN_TRACKS property.
detection.video.track.min.gap=2

# The DEFAULT minimum length of any tracks reported by the components. Track length <=1 will return all tracks.
# This may be overridden in a detection action by providing the MIN_TRACK_LENGTH property.
detection.video.track.min.length=1

# The DEFAULT minimum overlap that two tracks which are candidates for merging must overlap.
# This may be overridden in a detection action by providing the MIN_OVERLAP property.
detection.video.track.overlap.threshold=0.60

detection.models.dir.path=${mpf.share.path}/models/

detection.cuda.device.id=-1
detection.use.cpu.when.gpu.problem=false

detection.padding.x=0
detection.padding.y=0

detection.rotation.threshold=1.0
detection.rotation.fill.color=BLACK

detection.http.retry.max.attempts=10
detection.http.retry.initial.delay.ms=200
detection.http.retry.max.delay.ms=30000

###################################
# Pipeline and Node Configuration #
###################################

data.dir=${mpf.share.path}/data
data.template.dir=classpath:templates

data.algorithms.file=${data.dir}/Algorithms.json
data.algorithms.template=${data.template.dir}/Algorithms.json

data.actions.file=${data.dir}/Actions.json
data.actions.template=${data.template.dir}/Actions.json

data.tasks.file=${data.dir}/Tasks.json
data.tasks.template=${data.template.dir}/Tasks.json

data.pipelines.file=${data.dir}/Pipelines.json
data.pipelines.template=${data.template.dir}/Pipelines.json

data.nodemanagerpalette.file=${data.dir}/nodeServicesPalette.json
data.nodemanagerpalette.template=${data.template.dir}/nodeServicesPalette.json

data.nodemanagerconfig.file=${data.dir}/nodeManagerConfig.xml
data.nodemanagerconfig.template=${data.template.dir}/nodeManagerConfig.xml

data.streamingprocesses.file=${data.dir}/streamingServices.json
data.streamingprocesses.template=${data.template.dir}/streamingServices.json

#############################
# Component Upload Settings #
#############################

#this is just the name of the directory, not a full file path!
component.upload.dir.name=components

data.component.info.file=${data.dir}/components.json
data.component.info.template=${data.template.dir}/components.json


mpf.ansible.role.child.path=${env:MPF_HOME}/manage/ansible/roles/child
mpf.ansible.compdeploy.path=${mpf.ansible.role.child.path}/tasks/compdeploy.yml
mpf.ansible.compremove.path=${mpf.ansible.role.child.path}/tasks/compremove.yml

############################
# Web Application Settings #
############################

# session timeout, in minutes
web.session.timeout=30

#top-level path to retrieve media (webServerMediaTreeBase)
# for normal users, $HOME should be the same as /home/${MPF_USER}, but not always
web.server.media.tree.base=${env:MPF_HOME}/share/remote-media

#the amount of files that can be submitted to the server for upload from "Browse" selection
web.max.file.upload.cnt=2500

# Enables / disables server side push of the job status changes.
web.broadcast.job.status.enabled=true

# web.broadcast.job.status.enabled is false, sets the time in milliseconds between updates of the jobs page.
# To disable polling, set this property to a negative number.
web.job.polling.interval=60000

######################
# Streaming Settings #
######################

# duration in milliseconds
streaming.stallAlert.detectionThreshold=30000
streaming.healthReport.callbackRate=30000

#########################
# Remote Media Settings #
#########################

# number of times to retry downloading remote media
remote.media.download.retries=3

# The time to sleep before trying to download remote media again (first retry), in milliseconds.
# The second retry will wait 2x this long, the third retry will wait 3x this long, etc.
# Ignored when downloading media from S3.
remote.media.download.sleep=5000

############################
# Node Management Settings #
############################

# If true, automatically configure a new node with instances of each service when it joins the cluster.
# If a previously configured node joins, the previous configuration will be used instead. The node will not be updated
# if a new component is registered after the node has been configured, unless it is unconfigured first.
# Any modifications to the node through the Nodes UI will remove the autoconfigured tag.
node.auto.config.enabled=false

# When automatically configuring a new node, use this number of instances of each service.
node.auto.config.num.services.per.component=1

# If true, automatically unconfigure an automatically-configured node when it leaves the cluster or the workflow manager
# is restarted. The next time the node joins it will need to be configured manually, unless node.auto.config.enabled is
# true. Nodes that are not automatically configured are unaffected.
node.auto.unconfig.enabled=false

###################
# Markup Settings #
###################

# If true, add a label to each detection box.
markup.labels.enabled=true

# Value in range [0.0, 1.0] that specifies how transparent the labels and frame number overlay should be.
# 0.0 is invisible (not recommended) and 1.0 is fully opaque.
markup.labels.alpha=0.5

# If true, use detection-level details to populate the bounding box labels. Otherwise, use track-level details.
markup.labels.from.detections=false

# Name of the text property to show in the label before the numeric property. If using track-level details, and this
# property is not present at the track level, then the detection property for the track's exemplar will be used.
# Leave empty to omit.
markup.labels.text.prop.to.show=CLASSIFICATION

# Name of the numeric property to show in the label after the text property. If using track-level details, and this
# property is not present at the track level, then the detection property for the track's exemplar will be used.
# Leave empty to omit. Set to CONFIDENCE to use the confidence value.
markup.labels.numeric.prop.to.show=CONFIDENCE

# Labels will always snap to the top-most corner of the box. If true, snap the label to the side of the corner that
# produces the least amount of overhang. If false, always show the label on the right side of the corner.
markup.labels.choose.side.enabled=true

# If true, generate the marked-up frame with a black border.
# Can be useful if boxes or labels extend beyond frame boundaries.
markup.border.enabled=false

# If true, and labels are enabled, use an icon to indicate exemplar detections.
markup.video.exemplar.icons.enabled=true

# If true, and labels are enabled, use icons to indicate the source of the bounding box. For example, if the box is the
# result of an algorithm detection, tracking performing gap fill, or Workflow Manager animation.
markup.video.box.source.icons.enabled=false

# If true, and labels are enabled, use icons to indicate if the object is considered moving or stationary. If using
# track-level details, and the "MOVING" property is not present at the track level, then the property for the track's
# exemplar will be used.
markup.video.moving.object.icons.enabled=false

# If true, add the frame number to each marked-up frame.
# This setting is independent of markup.labels.enabled.
markup.video.frame.numbers.enabled=true

# Use "vp9" to generate VP9-encoded .webm video files. Use "h264" to generate H.264-encoded .mp4 files. Use "mjpeg" to
# generate MJPEG-encoded .avi files. The .webm and .mp4 files can display in most browsers, and are higher quality, but
# take longer to generate.
markup.video.encoder=vp9

# https://trac.ffmpeg.org/wiki/Encode/VP9
# "The CRF value can be from 0-63. Lower values mean better quality. Recommended values range from 15-35,
#  with 31 being recommended for 1080p HD video."
markup.video.vp9.crf=31

##################
# Other Settings #
##################

log.parent.dir=${env:MPF_LOG_PATH}

config.mediaTypes.template=classpath:properties/mediaType.properties
config.user.template=classpath:properties/user.properties

startup.auto.registration.skip.spring=${startup.auto.registration.skip}

workflow.properties.file=classpath:workflow-properties.json
markup.properties.file=classpath:markup-properties.json

http.callback.timeout.ms=60000
http.callback.retries=10

warn.frame.count.diff=2

ties.db.url=
