[
    {
        "name": "FEED_FORWARD_TYPE",
        "description": "The type of feed-forward behavior. Controls how this algorithm will make use of the tracks generated in the previous pipeline stage. If this algorithm is used in the first pipeline stage then this property has no effect. Instead, the default segmenting behavior is used, where tracks from the previous stage are used to generate segments based on the TARGET_SEGMENT_LENGTH and MIN_SEGMENT_LENGTH properties. Can be set to “NONE”, “FRAME”, or “SUPERSET_REGION”. If set to “NONE”, the default segmenting behavior is used. If set to “FRAME” or “SUPERSET_REGION”, then the segment length properties are ignored and instead this algorithm will process one segment per track generated in the previous stage. If set to “FRAME”, then this algorithm will ignore the regions associated with previous detections and instead process the entire frame associated with each of those detections. If set to “SUPERSET_REGION”, then this algorithm will generate a superset region for each of the previous tracks – a bounding box of constant size and position that encloses all of the track’s detection regions. This algorithm will only process the data within the superset region.",
        "type": "STRING",
        "defaultValue": "NONE",
        "mediaTypes": ["VIDEO", "IMAGE"]
    },
    {
        "name": "FEED_FORWARD_TOP_CONFIDENCE_COUNT",
        "description": "Only applies if FEED_FORWARD_TYPE is set to a value other than “NONE”. If set to a value <= 0, then for each track generated in the previous pipeline stage, this algorithm will process the frame associated with each detection in that track, ignoring frames that don’t have detections. If FEED_FORWARD_TYPE is set to “FRAME”, then the entire frame is processed. If FEED_FORWARD_TYPE is set to “SUPERSET_REGION”, then only the superset region for those frames is processed. If this property is set to “1” then only the exemplar frame for each of the previous tracks is processed. If this property is set to a value > 1, say 5, then each of the detections in the previous track are sorted by confidence and this algorithm will only process the frames associated with the top 5 detections with the highest confidence. For detections with the same confidence values, it will select those with a lower frame index. If the track contains less than 5 detections, then all of the available detections are used. In practice, setting this property to a value > 1 has no effect on image and audio jobs because each track only contains one detection.",
        "type": "INT",
        "defaultValue": "0",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "USE_KEY_FRAMES",
        "description": "When true the component will only look at key frames (I-frames) from the input video. Can be used in conjunction with FRAME_INTERVAL. For example, when USE_KEY_FRAMES is true, and FRAME_INTERVAL is set to \"2\", then every other key frame will be processed.",
        "type": "BOOLEAN",
        "defaultValue": "false",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "OUTPUT_ARTIFACTS_AND_EXEMPLARS_ONLY",
        "description": "The JSON output object will contain only the exemplar and extracted artifacts for each track.",
        "type": "BOOLEAN",
        "propertiesKey": "mpf.output.objects.artifacts.and.exemplars.only",
        "mediaTypes": ["VIDEO","IMAGE"]
    },
    {
        "name": "OUTPUT_LAST_TASK_ONLY",
        "description": "The JSON output object will contain the exemplar and extracted artifacts for each track in the last task only.",
        "type": "BOOLEAN",
        "propertiesKey": "mpf.output.objects.last.task.only",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "OUTPUT_MERGE_WITH_PREVIOUS_TASK",
        "description": "Tasks with this property set to true will replace the preceding task's tracks in the JSON output object. Those tracks will inherit the track type and algorithm from the preceding task's tracks.",
        "type": "BOOLEAN",
        "defaultValue": "false",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "ARTIFACT_EXTRACTION_POLICY",
        "description": "The policy for extracting artifacts (e.g., frames) from a medium. The value of this property MUST be one of the following choices. NONE: No artifact extraction will be performed. VISUAL_TYPES_ONLY: Extract artifacts only for tracks associated with a \"visual\" data type. ALL_TYPES: Extract artifacts regardless of data type. ALL_DETECTIONS: Extract artifacts for all detections in the track. With the VISUAL_TYPES_ONLY or ALL_TYPES policy, artifacts will be extracted according to the ARTIFACT_EXTRACTION_POLICY* properties. With the NONE and ALL_DETECTIONS policies, those settings are ignored.",
        "type": "STRING",
        "propertiesKey": "detection.artifact.extraction.policy",
        "mediaTypes": ["VIDEO","IMAGE"]
    },
    {
        "name": "ARTIFACT_EXTRACTION_POLICY_CROPPING",
        "description": "If true, an artifact will be extracted for each detection in each frame selected according to the ARTIFACT_EXTRACTION_POLICY* properties. The extracted artifact will be cropped to the width and height of the detection bounding box, instead of extracting the entire frame. If false, the entire frame will be extracted.",
        "type": "BOOLEAN",
        "propertiesKey": "detection.artifact.extraction.policy.cropping",
        "mediaTypes": ["VIDEO","IMAGE"]
    },
    {
        "name": "ARTIFACT_EXTRACTION_POLICY_EXEMPLAR_FRAME_PLUS",
        "description": "Extract the exemplar frame from the track, plus N frames before and after the exemplar. If N = 0, then only the exemplar frame will be extracted. If N > 0, then the exemplar frame plus N frames before and after it will be extracted, if they exist within the track. If N < 0, then this property is disabled. The exemplar will not be extracted.",
        "type": "INT",
        "propertiesKey": "detection.artifact.extraction.policy.exemplar.frame.plus",
        "mediaTypes": ["VIDEO","IMAGE"]
    },
    {
        "name": "ARTIFACT_EXTRACTION_POLICY_FIRST_FRAME",
        "description": "Extract the first frame from the track.",
        "type": "BOOLEAN",
        "propertiesKey": "detection.artifact.extraction.policy.first.frame",
        "mediaTypes": ["VIDEO","IMAGE"]
    },
    {
        "name": "ARTIFACT_EXTRACTION_POLICY_MIDDLE_FRAME",
        "description": "Extract the frame with a detection that is closest to the middle frame from the track.",
        "type": "BOOLEAN",
        "propertiesKey": "detection.artifact.extraction.policy.middle.frame",
        "mediaTypes": ["VIDEO","IMAGE"]
    },
    {
        "name": "ARTIFACT_EXTRACTION_POLICY_LAST_FRAME",
        "description": "Extract the last frame from the track.",
        "type": "BOOLEAN",
        "propertiesKey": "detection.artifact.extraction.policy.last.frame",
        "mediaTypes": ["VIDEO","IMAGE"]
    },
    {
        "name": "ARTIFACT_EXTRACTION_POLICY_TOP_CONFIDENCE_COUNT",
        "description": "The detections in a track will be sorted by confidence and then the N detections with the highest confidence will be extracted, up to the number of available detections, where N is an integer greater than 0. If N is less than or equal to 0, then this policy is disabled.",
        "type": "INT",
        "propertiesKey": "detection.artifact.extraction.policy.top.confidence.count",
        "mediaTypes": ["VIDEO","IMAGE"]
    },
    {
        "name": "FRAME_INTERVAL",
        "description": "Controls whether the component performs detection on every frame in the video segment, or skips some frames at a regular interval. Must be set to a value >= 0. If set to 0 or 1, a frame interval of 1 will be used, meaning that detection is performed on every frame. If set to N > 1, every N-1 frames will be skipped.",
        "type": "INT",
        "propertiesKey": "detection.sampling.interval",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "FRAME_RATE_CAP",
        "description": "The threshold on the maximum number of frames to process in the video segment within one second of the native video time. If set to a value > 0, then an internal frame interval value is calculated as max(1, floor(mediaNativeFPS / FRAME_RATE_CAP)) and the FRAME_INTERVAL property is not used. To disable, set to a value <= 0. When disabled, the FRAME_INTERVAL property is used, if valid.",
        "type": "INT",
        "propertiesKey": "detection.frame.rate.cap",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "CONFIDENCE_THRESHOLD",
        "description": "The minimum confidence score which must be met or exceeded. Detections below this threshold are silently discarded.",
        "type": "DOUBLE",
        "propertiesKey": "detection.confidence.threshold",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "MIN_GAP_BETWEEN_SEGMENTS",
        "description": "In the context of videos, the minimum number of frames between segments which are not adjacent. Value must be greater than or equal to 1.",
        "type": "INT",
        "propertiesKey": "detection.segment.minimum.gap",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "TARGET_SEGMENT_LENGTH",
        "description": "In the context of constant frame rate videos, the preferred length of segments which are to be processed by this algorithm. Value is expected to be greater than 10.",
        "type": "INT",
        "propertiesKey": "detection.segment.target.length",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "VFR_TARGET_SEGMENT_LENGTH",
        "description": "In the context of variable frame rate videos, the preferred length of segments which are to be processed by this algorithm. Value is expected to be greater than 10.",
        "type": "INT",
        "propertiesKey": "detection.vfr.segment.target.length",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "MIN_SEGMENT_LENGTH",
        "description": "In the context of constant frame rate videos, the minimum length of a segment which will be processed by this algorithm. Value must be greater than 0.",
        "type": "INT",
        "propertiesKey": "detection.segment.minimum.length",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "VFR_MIN_SEGMENT_LENGTH",
        "description": "In the context of variable segment length videos, the minimum length of a segment which will be processed by this algorithm. Value must be greater than 0.",
        "type": "INT",
        "propertiesKey": "detection.vfr.segment.minimum.length",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "MERGE_TRACKS",
        "description": "In the context of videos, when set to true, attempt to merge tracks spanning segment boundaries.",
        "type": "BOOLEAN",
        "propertiesKey": "detection.video.track.merging.enabled",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "MIN_GAP_BETWEEN_TRACKS",
        "description": "In the context of videos, similar tracks with less than this number of frames between them will be merged into a single track. If MERGE_TRACKS is false, this has no effect.",
        "type": "INT",
        "propertiesKey": "detection.video.track.min.gap",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "MIN_TRACK_LENGTH",
        "description": "In the context of videos, defines the minimum track length in frames. Tracks shorter than this minimum length will be silently discarded.",
        "type": "INT",
        "propertiesKey": "detection.video.track.min.length",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "MIN_OVERLAP",
        "description": "In the context of videos, the minimum overlap between detection bounding boxes for adjacent tracks to be considered continuous. Value is expected to be between 0 and 1.",
        "type": "DOUBLE",
        "propertiesKey": "detection.video.track.overlap.threshold",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "SEARCH_REGION_ENABLE_DETECTION",
        "description": "Enable cropping.",
        "type": "BOOLEAN",
        "defaultValue": "false",
        "mediaTypes": ["VIDEO", "IMAGE"]
    },
    {
        "name": "SEARCH_REGION_TOP_LEFT_X_DETECTION",
        "description": "X coordinate for top left corner of cropped frame. If this string contains the % sign, then its numeric value will be interpreted as a percentage of the width of the frame, and its value will be capped between 0% and 100%, inclusive. If this string does not contain the % sign, then it will be interpreted as a pixel position. If negative, the top left X position will be set to 0.",
        "type": "STRING",
        "defaultValue": "-1",
        "mediaTypes": ["VIDEO", "IMAGE"]
    },
    {
        "name": "SEARCH_REGION_TOP_LEFT_Y_DETECTION",
        "description": "Y coordinate for top left corner of cropped frame. If this string contains the % sign, then its numeric value will be interpreted as a percentage of the height of the frame, and its value will be capped between 0% and 100%, inclusive. If this string does not contain the % sign, then it will be interpreted as a pixel position. If negative, the top left Y position will be set to 0.",
        "type": "STRING",
        "defaultValue": "-1",
        "mediaTypes": ["VIDEO", "IMAGE"]
    },
    {
        "name": "SEARCH_REGION_BOTTOM_RIGHT_X_DETECTION",
        "description": "X coordinate for bottom right corner of cropped frame. If this string contains the % sign, then its numeric value will be interpreted as a percentage of the width of the frame, and its value will be capped between 0% and 100%, inclusive. If this string does not contain the % sign, then it will be interpreted as a pixel position. If zero or negative, the bottom right X position will be set to the width of the frame.",
        "type": "STRING",
        "defaultValue": "-1",
        "mediaTypes": ["VIDEO", "IMAGE"]
    },
    {
        "name": "SEARCH_REGION_BOTTOM_RIGHT_Y_DETECTION",
        "description": "Y coordinate for bottom right corner of cropped frame. If this string contains the % sign, then its numeric value will be interpreted as a percentage of the height of the frame, and its value will be capped between 0% and 100%, inclusive. If this string does not contain the % sign, then it will be interpreted as a pixel position. If zero or negative, the bottom right Y position will be set to the height of the frame.",
        "type": "STRING",
        "defaultValue": "-1",
        "mediaTypes": ["VIDEO", "IMAGE"]
    },
    {
        "name": "ROTATION",
        "description": "Specifies the number of degrees in the clockwise direction that the media will be rotated. A floating point value in the interval [0.0, 360.0).",
        "type": "DOUBLE",
        "defaultValue": "0.0",
        "mediaTypes": ["VIDEO", "IMAGE"]
    },
    {
        "name": "HORIZONTAL_FLIP",
        "description": "Specifies whether or not the original media is flipped. Rotation occurs before flipping.",
        "type": "BOOLEAN",
        "defaultValue": "false",
        "mediaTypes": ["VIDEO", "IMAGE"]
    },
    {
        "name": "AUTO_ROTATE",
        "description": "Specifies whether not to rotate media based on EXIF data or video metadata.",
        "type": "BOOLEAN",
        "defaultValue": "true",
        "mediaTypes": ["VIDEO", "IMAGE"]
    },
    {
        "name": "AUTO_FLIP",
        "description": "Specifies whether or not to flip media based on EXIF data.",
        "type": "BOOLEAN",
        "defaultValue": "true",
        "mediaTypes": ["VIDEO", "IMAGE"]
    },
    {
        "name": "DETECTION_PADDING_X",
        "description": "If this string contains the % sign, then its numeric value will be interpreted as a percentage of the width of the detection. If this string does not contain the % sign, then it will be interpreted as an exact number of pixels. A negative value will shrink the detection region. Percentages can include a decimal place and be > 100%, but must be > -50%. If the detection region is shrunk to nothing, the new width will be set to one pixel, and the detection properties will include SHRUNK_TO_NOTHING with a value of TRUE.",
        "type": "STRING",
        "propertiesKey": "detection.padding.x",
        "mediaTypes": ["VIDEO", "IMAGE"]
    },
    {
        "name": "DETECTION_PADDING_Y",
        "description": "If this string contains the % sign, then its numeric value will be interpreted as a percentage of the height of the detection. If this string does not contain the % sign, then it will be interpreted as an exact number of pixels. A negative value will shrink the detection region. Percentages can include a decimal place and be > 100%, but must be > -50%. If the detection region is shrunk to nothing, the new height will be set to one pixel, and the detection properties will include SHRUNK_TO_NOTHING with a value of TRUE.",
        "type": "STRING",
        "propertiesKey": "detection.padding.y",
        "mediaTypes": ["VIDEO", "IMAGE"]
    },
    {
        "name": "ROTATION_THRESHOLD",
        "description": "The minimum number of degrees required to actually perform frame rotation. When the amount of rotation is less than ROTATION_THRESHOLD, components will behave as if there is no rotation.",
        "type": "DOUBLE",
        "propertiesKey": "detection.rotation.threshold",
        "mediaTypes": ["VIDEO", "IMAGE"]
    },
    {
        "name": "ROTATION_FILL_COLOR",
        "description": "The fill color to use when doing non-orthogonal rotation. Must either be BLACK or WHITE. When doing a non-orthogonal rotation, some pixels will need to be included that were not in the original image. This property controls the color of those undefined pixels.",
        "type": "STRING",
        "propertiesKey": "detection.rotation.fill.color",
        "mediaTypes": ["VIDEO", "IMAGE"]
    },
    {
        "name": "MOVING_TRACK_LABELS_ENABLED",
        "description": "In the context of videos, when set to true, attempt to label tracks as either moving or not moving objects.",
        "type": "BOOLEAN",
        "propertiesKey": "detection.moving.track.labels.enabled",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "MOVING_TRACKS_ONLY",
        "description": "In the context of videos, when set to true, remove any tracks that were marked as not moving.",
        "type": "BOOLEAN",
        "propertiesKey": "detection.moving.track.outputs.only",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "MOVING_TRACK_MAX_IOU",
        "description": "In the context of videos, the maximum intersection of union(IoU) overlap between detection bounding boxes and the average per-track bounding box for objects to be considered moving. Value is expected to be between 0 and 1. Note that the lower IoU, the more likely the object is moving.",
        "type": "DOUBLE",
        "propertiesKey": "detection.moving.track.max.iou",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "MOVING_TRACK_MIN_DETECTIONS",
        "description": "In the context of videos, the minimum number of moving detections for a track to be labeled as moving.",
        "type": "DOUBLE",
        "propertiesKey": "detection.moving.track.min.detections",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "COMPONENT_HTTP_RETRY_MAX_ATTEMPTS",
        "description": "The maximum number of times a component should attempt an HTTP request before failing.",
        "type": "INT",
        "propertiesKey": "detection.http.retry.max.attempts",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "COMPONENT_HTTP_RETRY_INITIAL_DELAY_MS",
        "description": "The number of milliseconds a component should initially wait before retrying an HTTP request. Each subsequent attempt will wait for double the amount of time of the previous attempt.",
        "type": "INT",
        "propertiesKey": "detection.http.retry.initial.delay.ms",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "COMPONENT_HTTP_RETRY_MAX_DELAY_MS",
        "description": "The maximum number of a milliseconds a component should wait before retrying an HTTP request. If the component receives an error response with the \"Retry-After\" header set to a value greater than this propertry, the value from the header will be used.",
        "type": "INT",
        "propertiesKey": "detection.http.retry.max.delay.ms",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "TIES_DB_URL",
        "description": "When provided, information about completed jobs will be sent to the specified TiesDb server.",
        "type": "STRING",
        "propertiesKey": "ties.db.url",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "SKIP_TIES_DB_CHECK",
        "description": "When true, TiesDb won't be checked for a compatible job before processing media.",
        "type": "BOOLEAN",
        "propertiesKey": "ties.db.skip.check",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "S3_ACCESS_KEY",
        "description": "The access key that will be used when downloading and uploading to S3.",
        "type": "STRING",
        "propertiesKey": "s3.access.key",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "S3_SECRET_KEY",
        "description": "The secret key that will be used when downloading and uploading to S3.",
        "type": "STRING",
        "propertiesKey": "s3.secret.key",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "S3_SESSION_TOKEN",
        "description": "Only required when the S3 bucket is configured to require a session key. This generally occurs when multi-factor authentication is required. OpenMPF does not handle generating the session key.",
        "type": "STRING",
        "propertiesKey": "s3.session.token",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "S3_RESULTS_BUCKET",
        "description": "URI to bucket where result objects should be stored. To disable the upload of result objects, do not provide a value for this property.",
        "type": "STRING",
        "propertiesKey": "s3.results.bucket",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "S3_UPLOAD_ONLY",
        "description": "When true, media will not be downloaded using S3 authentication. If S3_RESULTS_BUCKET is set, S3 authentication will be used to upload result objects.",
        "type": "BOOLEAN",
        "propertiesKey": "s3.upload.only",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "S3_REGION",
        "description": "Region to use when downloading and uploading to S3. For example: \"us-east-1\"",
        "type": "STRING",
        "propertiesKey": "s3.region",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "S3_USE_VIRTUAL_HOST",
        "description": "When true, the S3 client will be configured to use virtual host style access, otherwise path style access will be used. When using virtual host style access, the bucket name is part of domain name. For example: \"https://bucket.s3.amazonaws.com/object\". When path style access is used, the bucket name is the first segment in URL path. For example: \"https://s3.amazonaws.com/bucket/object\".",
        "type": "BOOLEAN",
        "propertiesKey": "s3.use.virtual.host",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "S3_HOST",
        "description": "When S3_USE_VIRTUAL_HOST is true, this should contain the S3 hostname without the bucket. For example, if the bucket URI is \"https://bucket.s3.amazonaws.com\", this should be set to \"s3.amazonaws.com\".",
        "type": "STRING",
        "propertiesKey": "s3.host",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "S3_UPLOAD_OBJECT_KEY_PREFIX",
        "description": "Specifies a prefix to prepend to object keys when uploading to S3.",
        "type": "STRING",
        "propertiesKey": "s3.upload.object.key.prefix",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "TIES_DB_S3_COPY_ENABLED",
        "description": "When true and a job is skipped because a compatible job is found in TiesDb, the results from the previous job will be copied to a different S3 bucket.",
        "type": "BOOLEAN",
        "propertiesKey": "ties.db.s3.copy.enabled",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "TIES_DB_COPY_SRC_S3_ACCESS_KEY",
        "description": "If a job is skipped because a compatible job was found in TiesDb, this is the S3 access key that will be used when getting the results from S3. If not provided, defaults to the value of S3_ACCESS_KEY.",
        "type": "STRING",
        "propertiesKey": "ties.db.copy.src.s3.access.key",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "TIES_DB_COPY_SRC_S3_SECRET_KEY",
        "description": "If a job is skipped because a compatible job was found in TiesDb, this is the S3 secret key that will be used when getting the results from S3. If not provided, defaults to the value of S3_SECRET_KEY.",
        "type": "STRING",
        "propertiesKey": "ties.db.copy.src.s3.secret.key",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "TIES_DB_COPY_SRC_S3_SESSION_TOKEN",
        "description": "If a job is skipped because a compatible job was found in TiesDb, this is the S3 session token that will be used when getting the results from S3. If not provided, defaults to the value of S3_SESSION_TOKEN.",
        "type": "STRING",
        "propertiesKey": "ties.db.copy.src.s3.session.token",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "TIES_DB_COPY_SRC_S3_REGION",
        "description": "If a job is skipped because a compatible job was found in TiesDb, this is the S3 region that will be used when getting the results from S3. If not provided, defaults to the value of S3_REGION.",
        "type": "STRING",
        "propertiesKey": "ties.db.copy.src.s3.region",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "TIES_DB_COPY_SRC_S3_USE_VIRTUAL_HOST",
        "description": "If a job is skipped because a compatible job was found in TiesDb, this enables virtual host style bucket URIs. If not provided, defaults to the value of S3_USE_VIRTUAL_HOST.",
        "type": "BOOLEAN",
        "propertiesKey": "ties.db.copy.src.s3.use.virtual.host",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "TIES_DB_COPY_SRC_S3_HOST",
        "description": "If a job is skipped because a compatible job was found in TiesDb, this is the S3 host that will be used when getting the results from S3. If not provided, defaults to the value of S3_HOST.",
        "type": "STRING",
        "propertiesKey": "ties.db.copy.src.s3.host",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "TIES_DB_COPY_SRC_S3_UPLOAD_OBJECT_KEY_PREFIX",
        "description": "If a job is skipped because a compatible job was found in TiesDb, this is the S3 object key prefix that will be used when getting the results from S3. If not provided, defaults to the value of S3_UPLOAD_OBJECT_KEY_PREFIX.",
        "type": "STRING",
        "propertiesKey": "ties.db.copy.src.s3.upload.object.key.prefix",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "SOURCE_MEDIA_ONLY",
        "description": "When set to true, the action will only be executed on the source media, not derivative media.",
        "type": "BOOLEAN",
        "defaultValue": "false",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "DERIVATIVE_MEDIA_ONLY",
        "description": "When set to true, the action will only be executed on derivative media, not the source media.",
        "type": "BOOLEAN",
        "defaultValue": "false",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "EXEMPLAR_POLICY",
        "description": "Sets the policy for determining a track's exemplar. When set to \"CONFIDENCE\" or anything other than a named policy, the detection with the maximum confidence is selected. The named policies are \"FIRST\" (select the detection with the minimum frame number), \"LAST\" (select the detection with the maximum frame number), and \"MIDDLE\" (select the detection with the frame number closest the middle frame of the track).",
        "type": "STRING",
        "defaultValue": "CONFIDENCE",
        "mediaTypes": ["VIDEO"]
    },
    {
        "name": "SKIP_MEDIA_INSPECTION",
        "description": "When set to true, Workflow Manager will attempt to use the media metadata provided in the job request to avoid performing media inspection.",
        "type": "BOOLEAN",
        "defaultValue": "false",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "FFPROBE_IGNORE_STDERR",
        "description": "When set to false and ffprobe produces error logging during media inspection, an error will be added to the media that was being inspected. When set to true, ffprobe's stderr is ignored.",
        "type": "BOOLEAN",
        "propertiesKey": "ffprobe.ignore.stderr",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "FFPROBE_STDERR_NUM_LINES",
        "description": "If \"FFPROBE_IGNORE_STDERR\" is false and ffprobe produces error logging, this value is the maximum number of lines of ffprobe's error logging that will be added to the media error.",
        "type": "INT",
        "propertiesKey": "ffprobe.stderr.num.lines",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "TRIGGER",
        "description": "Trigger condition for an action when feed forward is used. An action with a trigger of `TRACK_PROPERTY=VALUE` will only process feed forward tracks that have a track property named \"TRACK_PROPERTY\" set to \"VALUE\".",
        "type": "STRING",
        "defaultValue": "",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "CALLBACK_USE_OIDC",
        "description": "If Workflow Manager is configured to use OIDC and this property is true, an OAuth token will be included in the job completion callback.",
        "type": "BOOLEAN",
        "propertiesKey": "http.callback.use.oidc",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "TIES_DB_USE_OIDC",
        "description": "If Workflow Manager is configured to use OIDC and this property is true, an OAuth token will be included when communicating with TiesDb.",
        "type": "BOOLEAN",
        "propertiesKey": "ties.db.use.oidc",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    },
    {
        "name": "ROLL_UP_FILE",
        "description": "When provided, Workflow Manager will load the roll up JSON file from the specified path and apply the roll up to track and detection properties.",
        "type": "STRING",
        "defaultValue": "",
        "mediaTypes": ["VIDEO", "IMAGE", "AUDIO", "UNKNOWN"]
    }
]
